{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import scipy.stats as stats\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "plt.style.use('fivethirtyeight')\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "data = pd.read_csv(r\"D:\\all python works\\for thesis\\HepatitisCdata.csv\")\n",
    "\n",
    "\n",
    "data.drop([ \"Unnamed: 0\"], axis=1, inplace=True)\n",
    "print(data.columns)\n",
    "\n",
    "data.replace(to_replace=['0=Blood Donor', '0s=suspect Blood Donor', '1=Hepatitis',\n",
    "       '2=Fibrosis', '3=Cirrhosis'],\n",
    "             value=[0,1,2,3,4],inplace=True)\n",
    "\n",
    "data.replace(to_replace=['m','f'],\n",
    "             value=[0,1],inplace=True)\n",
    "data['ALB'].fillna(data['ALB'].mean(), inplace=True)\n",
    "data['ALP'].fillna(data['ALP'].mean(), inplace=True)\n",
    "data['CHOL'].fillna(data['CHOL'].mean(), inplace=True)\n",
    "data['PROT'].fillna(data['PROT'].mean(), inplace=True)\n",
    "data['ALT'].fillna(data['ALT'].mean(), inplace=True)\n",
    "data.info()\n",
    "\n",
    "\n",
    "\n",
    "                 #for training and testing\n",
    "                #Feature selection\n",
    "X_train=data.drop(columns=['Category','Sex','CREA'],axis=1)\n",
    "y_train=data['Category']\n",
    "\n",
    "print(data.columns)\n",
    "\n",
    "                # Standardize the features\n",
    "ss = StandardScaler()\n",
    "X_train = ss.fit_transform(X_train)\n",
    "\n",
    "                #model building\n",
    "from sklearn.svm import SVC\n",
    "svm = SVC()\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from xgboost import XGBClassifier\n",
    "xg = XGBClassifier()\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dt = DecisionTreeClassifier()\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression(max_iter=1000)\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy as np\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "import numpy as np\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, make_scorer\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from math import sqrt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Assuming you have defined and initialized the model lr, X_train, and y_train\n",
    "\n",
    "# Create StratifiedKFold with 10 folds\n",
    "#cv = StratifiedKFold(n_splits=7, shuffle=True, random_state=42)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Assuming you have defined and initialized the models xg, X_train, and y_train\n",
    "\n",
    "# xgBoost\n",
    "xg_acc = cross_val_score(estimator=xg, X=X_train, y=y_train, cv=5, scoring='accuracy')\n",
    "xg_prec_scorer = make_scorer(precision_score, average='macro', zero_division=1)\n",
    "xg_prec = cross_val_score(estimator=xg, X=X_train, y=y_train, cv=5, scoring=xg_prec_scorer)\n",
    "xg_rec_scorer = make_scorer(recall_score, average='macro', zero_division=1)\n",
    "xg_rec = cross_val_score(estimator=xg, X=X_train, y=y_train, cv=5, scoring=xg_rec_scorer)\n",
    "xg_f1_scorer = make_scorer(f1_score, average='macro', zero_division=1)\n",
    "xg_f1 = cross_val_score(estimator=xg, X=X_train, y=y_train, cv=5, scoring=xg_f1_scorer)\n",
    "xg_mae = cross_val_score(estimator=xg, X=X_train, y=y_train, cv=5, scoring='neg_mean_absolute_error')\n",
    "xg_rmse = cross_val_score(estimator=xg, X=X_train, y=y_train, cv=5, scoring='neg_mean_squared_error')\n",
    "actual_mae = abs(xg_mae.mean())\n",
    "print(f\"xgBoost Accuracy : {xg_acc.mean()}\")\n",
    "print(f\"xgBoost Precision : {xg_prec.mean()}\")\n",
    "print(f\"xgBoost Recall : {xg_rec.mean()}\")\n",
    "print(f\"xgBoost F1-Score : {xg_f1.mean()}\")\n",
    "print(f\"xgBoost MAE : {actual_mae.mean()}\")\n",
    "print(f\"xgBoost RMSE : {sqrt(-xg_rmse.mean())}\\n\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# SVM\n",
    "svm_acc = cross_val_score(estimator=svm, X=X_train, y=y_train, cv=5, scoring='accuracy')\n",
    "svm_prec_scorer = make_scorer(precision_score, average='macro', zero_division=1)\n",
    "svm_prec = cross_val_score(estimator=svm, X=X_train, y=y_train, cv=5, scoring=svm_prec_scorer)\n",
    "svm_rec_scorer = make_scorer(recall_score, average='macro', zero_division=1)\n",
    "svm_rec = cross_val_score(estimator=svm, X=X_train, y=y_train, cv=5, scoring=svm_rec_scorer)\n",
    "svm_f1_scorer = make_scorer(f1_score, average='macro', zero_division=1)\n",
    "svm_f1 = cross_val_score(estimator=svm, X=X_train, y=y_train, cv=5, scoring=svm_f1_scorer)\n",
    "svm_mae = cross_val_score(estimator=svm, X=X_train, y=y_train, cv=5, scoring='neg_mean_absolute_error')\n",
    "svm_rmse = cross_val_score(estimator=svm, X=X_train, y=y_train, cv=5, scoring='neg_mean_squared_error')\n",
    "actual_mae = abs(svm_mae.mean())\n",
    "print(f\"svm Accuracy : {svm_acc.mean()}\")\n",
    "print(f\"svm Precision : {svm_prec.mean()}\")\n",
    "print(f\"svm Recall : {svm_rec.mean()}\")\n",
    "print(f\"svm F1-Score : {svm_f1.mean()}\")\n",
    "print(f\"svm MAE : {actual_mae.mean()}\")\n",
    "print(f\"svm RMSE : {sqrt(-svm_rmse.mean())}\\n\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# lr\n",
    "lr_acc = cross_val_score(estimator=lr, X=X_train, y=y_train, cv=5, scoring='accuracy')\n",
    "lr_prec_scorer = make_scorer(precision_score, average='macro', zero_division=1)\n",
    "lr_prec = cross_val_score(estimator=lr, X=X_train, y=y_train, cv=5, scoring=lr_prec_scorer)\n",
    "lr_rec_scorer = make_scorer(recall_score, average='macro', zero_division=1)\n",
    "lr_rec = cross_val_score(estimator=lr, X=X_train, y=y_train, cv=5, scoring=lr_rec_scorer)\n",
    "lr_f1_scorer = make_scorer(f1_score, average='macro', zero_division=1)\n",
    "lr_f1 = cross_val_score(estimator=lr, X=X_train, y=y_train, cv=5, scoring=lr_f1_scorer)\n",
    "lr_mae = cross_val_score(estimator=lr, X=X_train, y=y_train, cv=5, scoring='neg_mean_absolute_error')\n",
    "lr_rmse = cross_val_score(estimator=lr, X=X_train, y=y_train, cv=5, scoring='neg_mean_squared_error')\n",
    "actual_mae = abs(lr_mae.mean())\n",
    "print(f\"logistic regression Accuracy : {lr_acc.mean()}\")\n",
    "print(f\"logistic regression Precision : {lr_prec.mean()}\")\n",
    "print(f\"logistic regression Recall : {lr_rec.mean()}\")\n",
    "print(f\"logistic regression F1-Score : {lr_f1.mean()}\")\n",
    "print(f\"logistic regression MAE : {actual_mae.mean()}\")\n",
    "print(f\"logistic regression RMSE : {sqrt(-lr_rmse.mean())}\\n\")\n",
    "\n",
    "rf_acc = cross_val_score(estimator=rf, X=X_train, y=y_train, cv=5, scoring='accuracy')\n",
    "rf_prec_scorer = make_scorer(precision_score, average='macro', zero_division=1)\n",
    "rf_prec = cross_val_score(estimator=rf, X=X_train, y=y_train, cv=5, scoring=rf_prec_scorer)\n",
    "rf_rec_scorer = make_scorer(recall_score, average='macro', zero_division=1)\n",
    "rf_rec = cross_val_score(estimator=rf, X=X_train, y=y_train, cv=5, scoring=rf_rec_scorer)\n",
    "rf_f1_scorer = make_scorer(f1_score, average='macro', zero_division=1)\n",
    "rf_f1 = cross_val_score(estimator=rf, X=X_train, y=y_train, cv=5, scoring=rf_f1_scorer)\n",
    "rf_mae = cross_val_score(estimator=rf, X=X_train, y=y_train, cv=5, scoring='neg_mean_absolute_error')\n",
    "rf_rmse = cross_val_score(estimator=rf, X=X_train, y=y_train, cv=5, scoring='neg_mean_squared_error')\n",
    "actual_mae = abs(rf_mae.mean())\n",
    "print(f\"random forest Accuracy : {rf_acc.mean()}\")\n",
    "print(f\"random forest Precision : {rf_prec.mean()}\")\n",
    "print(f\"random forest Recall : {rf_rec.mean()}\")\n",
    "print(f\"random forest F1-Score : {rf_f1.mean()}\")\n",
    "print(f\"random forest MAE : {actual_mae.mean()}\")\n",
    "print(f\"random forest RMSE : {sqrt(-rf_rmse.mean())}\\n\")\n",
    "\n",
    "dt_acc = cross_val_score(estimator=dt, X=X_train, y=y_train, cv=5, scoring='accuracy')\n",
    "dt_prec_scorer = make_scorer(precision_score, average='macro', zero_division=1)\n",
    "dt_prec = cross_val_score(estimator=dt, X=X_train, y=y_train, cv=5, scoring=dt_prec_scorer)\n",
    "dt_rec_scorer = make_scorer(recall_score, average='macro', zero_division=1)\n",
    "dt_rec = cross_val_score(estimator=dt, X=X_train, y=y_train, cv=5, scoring=dt_rec_scorer)\n",
    "dt_f1_scorer = make_scorer(f1_score, average='macro', zero_division=1)\n",
    "dt_f1 = cross_val_score(estimator=dt, X=X_train, y=y_train, cv=5, scoring=dt_f1_scorer)\n",
    "dt_mae = cross_val_score(estimator=dt, X=X_train, y=y_train, cv=5, scoring='neg_mean_absolute_error')\n",
    "dt_rmse = cross_val_score(estimator=dt, X=X_train, y=y_train, cv=5, scoring='neg_mean_squared_error')\n",
    "actual_mae = abs(dt_mae.mean())\n",
    "print(f\"decision tree Accuracy : {dt_acc.mean()}\")\n",
    "print(f\"decision tree Precision : {dt_prec.mean()}\")\n",
    "print(f\"decision tree Recall : {dt_rec.mean()}\")\n",
    "print(f\"decision tree F1-Score : {dt_f1.mean()}\")\n",
    "print(f\"decision tree MAE : {actual_mae.mean()}\")\n",
    "print(f\"decision tree RMSE : {sqrt(-dt_rmse.mean())}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensemble LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf.fit(X_train, y_train)\n",
    "svm.fit(X_train, y_train)\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "xg.fit(X_train, y_train)\n",
    "dt.fit(X_train, y_train)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "#lr = LogisticRegression(max_iter=10000)\n",
    "#lr.fit(X_train, y_train)\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "estimator_list=[\n",
    "    ('rf',rf),\n",
    "    ('svm',svm),\n",
    "    \n",
    "    ('xg',xg),\n",
    "    ('dt',dt)\n",
    "    ]\n",
    "stack_model=StackingClassifier(\n",
    "    estimators=estimator_list,final_estimator=LogisticRegression(max_iter=10000)\n",
    ")\n",
    "stack_acc = cross_val_score(estimator=stack_model, X=X_train, y=y_train, cv=5, scoring='accuracy')\n",
    "stack_prec_scorer = make_scorer(precision_score, average='macro', zero_division=1)\n",
    "stack_prec = cross_val_score(estimator=stack_model, X=X_train, y=y_train, cv=5, scoring=stack_prec_scorer)\n",
    "stack_rec_scorer = make_scorer(recall_score, average='macro', zero_division=1)\n",
    "stack_rec = cross_val_score(estimator=stack_model, X=X_train, y=y_train, cv=5, scoring=stack_rec_scorer)\n",
    "stack_f1_scorer = make_scorer(f1_score, average='macro', zero_division=1)\n",
    "stack_f1 = cross_val_score(estimator=stack_model, X=X_train, y=y_train, cv=5, scoring=stack_f1_scorer)\n",
    "stack_mae = cross_val_score(estimator=stack_model, X=X_train, y=y_train, cv=5, scoring='neg_mean_absolute_error')\n",
    "stack_rmse = cross_val_score(estimator=stack_model, X=X_train, y=y_train, cv=5, scoring='neg_mean_squared_error')\n",
    "actual_mae = abs(stack_mae.mean())\n",
    "print(f\"stacked model Accuracy : {stack_acc.mean()}\")\n",
    "print(f\"stacked model Precision : {stack_prec.mean()}\")\n",
    "print(f\"stacked model Recall : {stack_rec.mean()}\")\n",
    "print(f\"stacked model F1-Score : {stack_f1.mean()}\")\n",
    "print(f\"stacked MAE : {actual_mae.mean()}\")\n",
    "print(f\"stacked RMSE : {sqrt(-stack_rmse.mean())}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensemble XB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "svm = SVC()\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dt = DecisionTreeClassifier()\n",
    "rf.fit(X_train, y_train)\n",
    "svm.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "dt.fit(X_train, y_train)\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "lr=LogisticRegression(max_iter=100000)\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "estimator_list=[\n",
    "    ('rf',rf),\n",
    "    ('svm',svm),\n",
    "    ('lr',lr),\n",
    "    ('dt',dt)\n",
    "    ]\n",
    "stack_model=StackingClassifier(\n",
    "    estimators=estimator_list,final_estimator= XGBClassifier()\n",
    "\n",
    ")\n",
    "stack_acc = cross_val_score(estimator=stack_model, X=X_train, y=y_train, cv=7, scoring='accuracy')\n",
    "stack_prec_scorer = make_scorer(precision_score, average='macro', zero_division=1)\n",
    "stack_prec = cross_val_score(estimator=stack_model, X=X_train, y=y_train, cv=7, scoring=stack_prec_scorer)\n",
    "stack_rec_scorer = make_scorer(recall_score, average='macro', zero_division=1)\n",
    "stack_rec = cross_val_score(estimator=stack_model, X=X_train, y=y_train, cv=7, scoring=stack_rec_scorer)\n",
    "stack_f1_scorer = make_scorer(f1_score, average='macro', zero_division=1)\n",
    "stack_f1 = cross_val_score(estimator=stack_model, X=X_train, y=y_train, cv=7, scoring=stack_f1_scorer)\n",
    "stack_mae = cross_val_score(estimator=stack_model, X=X_train, y=y_train, cv=7, scoring='neg_mean_absolute_error')\n",
    "stack_rmse = cross_val_score(estimator=stack_model, X=X_train, y=y_train, cv=7, scoring='neg_mean_squared_error')\n",
    "actual_mae = abs(stack_mae.mean())\n",
    "print(f\"stacked model Accuracy : {stack_acc.mean()}\")\n",
    "print(f\"stacked model Precision : {stack_prec.mean()}\")\n",
    "print(f\"stacked model Recall : {stack_rec.mean()}\")\n",
    "print(f\"stacked model F1-Score : {stack_f1.mean()}\")\n",
    "print(f\"stacked MAE : {actual_mae.mean()}\")\n",
    "print(f\"stacked RMSE : {sqrt(-stack_rmse.mean())}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensemble Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "svm = SVC()\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from xgboost import XGBClassifier\n",
    "xg = XGBClassifier()\n",
    "xg.fit(X_train, y_train)\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dt = DecisionTreeClassifier()\n",
    "\n",
    "svm.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "dt.fit(X_train, y_train)\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "lr=LogisticRegression(max_iter=100000)\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "estimator_list=[\n",
    "    ('xg',xg),\n",
    "    ('svm',svm),\n",
    "    ('lr',lr),\n",
    "    ('dt',dt)\n",
    "    ]\n",
    "stack_model=StackingClassifier(\n",
    "    estimators=estimator_list,final_estimator= RandomForestClassifier()\n",
    "\n",
    ")\n",
    "stack_acc = cross_val_score(estimator=stack_model, X=X_train, y=y_train, cv=7, scoring='accuracy')\n",
    "stack_prec_scorer = make_scorer(precision_score, average='macro', zero_division=1)\n",
    "stack_prec = cross_val_score(estimator=stack_model, X=X_train, y=y_train, cv=7, scoring=stack_prec_scorer)\n",
    "stack_rec_scorer = make_scorer(recall_score, average='macro', zero_division=1)\n",
    "stack_rec = cross_val_score(estimator=stack_model, X=X_train, y=y_train, cv=7, scoring=stack_rec_scorer)\n",
    "stack_f1_scorer = make_scorer(f1_score, average='macro', zero_division=1)\n",
    "stack_f1 = cross_val_score(estimator=stack_model, X=X_train, y=y_train, cv=7, scoring=stack_f1_scorer)\n",
    "stack_mae = cross_val_score(estimator=stack_model, X=X_train, y=y_train, cv=7, scoring='neg_mean_absolute_error')\n",
    "stack_rmse = cross_val_score(estimator=stack_model, X=X_train, y=y_train, cv=7, scoring='neg_mean_squared_error')\n",
    "actual_mae = abs(stack_mae.mean())\n",
    "print(f\"stacked model Accuracy : {stack_acc.mean()}\")\n",
    "print(f\"stacked model Precision : {stack_prec.mean()}\")\n",
    "print(f\"stacked model Recall : {stack_rec.mean()}\")\n",
    "print(f\"stacked model F1-Score : {stack_f1.mean()}\")\n",
    "print(f\"stacked MAE : {actual_mae.mean()}\")\n",
    "print(f\"stacked RMSE : {sqrt(-stack_rmse.mean())}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "paper2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
